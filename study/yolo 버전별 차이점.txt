yolo 버전별 차이점

https://velog.io/@qtly_u/n4ptcz54
https://scottxchoo.xyz/yolo-v1-v8/
https://velog.io/@jjun-ho/Object-Detection-2-YOLO-%EB%AA%A8%EB%8D%B8-%EB%B9%84%EA%B5%90
https://m.blog.naver.com/ehdrndd/222368500800


YOLOv1
객체 감지를 위한 단일 신경망 사용.
이미지를 S x S 그리드로 나누고 각 그리드 셀에서 B개의 바운딩 박스와 객체 클래스를 예측.
상대적으로 빠르지만, 작은 객체나 복잡한 배경에서는 정확도가 떨어짐.
# S = 7, B = 2

YOLOv2
고해상도 학습 이미지 사용으로 정확도 향상.
배치 정규화(batch normalization) 사용으로 안정성 및 학습 속도 향상.
앵커 박스(각 셀 당 5개) 도입으로 다양한 객체 크기에 대한 감지 성능 개선.
다양한 데이터셋을 활용한 다중 클래스 학습 가능.

YOLOv3
다중 스케일 특징 추출(multi-scale features) 사용으로 작은 객체 감지 성능 향상.
Darknet-53 백본 네트워크 사용으로 더 깊고 정확한 특징 추출.
각 그리드 셀당 3개의 예측 상자(anchor box)를 사용하여 성능 향상.
보다 세밀한 특징 맵 활용으로 정확도 개선.
Sigmoid를 사용한 다중 라벨 예측

YOLOv4
CSPDarknet53 백본 네트워크 사용으로 모델의 파라미터 수와 계산 복잡도 감소.
다양한 트릭 및 기법 도입으로 학습 및 추론 성능 향상.
(CIoU loss, Mish activation, Mosaic data augmentation 등 그당시 SOTA 들) 
향상된 데이터 증강 기법 및 학습 전략으로 더 높은 정확도와 속도 제공.
다중 스케일 예측과 병렬 예측 사용으로 성능 최적화.
단일 gpu 훈련에 더 효율적이고 적합하게 바뀜. 1080ti, 2080ti 에서도 학습 시킬수 있게 만듦

YOLOv5
PyTorch 기반으로 개발되어 더 쉽고 유연한 모델 학습과 배포 가능.
다양한 크기의 모델(예: YOLOv5s, YOLOv5m, YOLOv5l, YOLOv5x) 제공으로 사용자의 필요에 맞게 선택 가능.
AutoAnchor, Multi-resolution training 등 추가 기법 도입으로 모델의 적응성 및 성능 향상.
더욱 효율적인 학습 및 추론 속도로 실시간 애플리케이션에 적합.

YOLOv6
개선된 백본 네트워크와 넥(Network) 구조 사용으로 성능 향상.
지능형 앵커 프리(mechanism) 도입으로 다양한 객체 크기에 대한 성능 개선.
데이터셋의 다양성과 증가된 학습 데이터로 더 나은 일반화 성능 제공.
TensorRT와의 호환성 개선으로 더욱 빠른 추론 속도 제공.

YOLOv7
모델 아키텍처 최적화를 통해 더 빠른 추론 속도와 높은 정확도 달성.
새로운 학습 기술과 데이터 증강 기법 도입으로 성능 향상.
기존의 다양한 YOLO 버전과의 호환성 유지하면서도 최신 기술 적용.
작은 객체 감지 성능을 더욱 개선하기 위한 추가적인 연구 및 개발 포함.

YOLOv8
최신 트랜스포머 기반 아키텍처 도입으로 성능 극대화.
모델 경량화 및 효율성 개선을 통해 모바일 및 임베디드 장치에서의 사용 최적화.
더욱 정교한 데이터 증강 기법과 최적화된 학습 알고리즘 사용.
고해상도 이미지 처리 능력 향상 및 다양한 환경에서의 실시간 성능 개선.
